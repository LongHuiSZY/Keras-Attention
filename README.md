## Attention：注意力机制在Keras当中的实现
---

### 目录
1. [所需环境 Environment](#所需环境)
2. [LSTM中的注意力机制](#LSTM中的注意力机制)
3. [conv中的注意力机制](#conv中的注意力机制)

### 所需环境
tensorflow-gpu==1.13.1  
keras==2.1.5  

### LSTM中的注意力机制
在LSTM中，主要是把每一个时间节点，即每一个STEP的输出作为特征，利用注意力机制对每一个时间节点的特征进行权重选取。

### conv中的注意力机制
在卷积神经网络中，主要是利用注意力机制把特征层中的每一层特征的权重进行计算。
